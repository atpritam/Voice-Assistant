
================================================================================
COMPREHENSIVE TEST
================================================================================


Pipeline: Algorithmic -> Semantic -> LLM (Ollama)
Semantic Model: all-mpnet-base-v2
LLM Model: llama3.2:3b-instruct-q4_K_M
Mode: TEST MODE (intent recognition only)

Boost Engine: True
Edge Cases Included: True

Test Dataset Size: 400 queries


OVERALL RESULTS
--------------------------------------------------------------------------------
Accuracy: 98.00%
Correct: 392 / 400
Avg Query Time: 19.8ms
Queries/s: 50.4

LAYER USAGE
--------------------------------------------------------------------------------
Algorithmic : 336 ( 84.0%)  Acc: 98.51%
Semantic    :  43 ( 10.8%)  Acc: 95.35%
LLM         :  21 (  5.2%)  Acc: 95.24%

CONFIDENCE LEVELS
--------------------------------------------------------------------------------
High (â‰¥0.8)           : 285 ( 71.2%)
Medium (0.6-0.8)      :  96 ( 24.0%)
Low (<0.6)            :  19 (  4.8%)

INCORRECT PREDICTIONS
--------------------------------------------------------------------------------

1. 'Can you take my order?' -> delivery (exp: order, conf: 0.78, layer: algorithmic)

2. 'Do you have late night hours' -> delivery (exp: hours_location, conf: 0.90, layer: algorithmic)

3. 'How do I get to your location' -> delivery (exp: hours_location, conf: 0.50, layer: semantic)

4. 'Hey there, I'm looking to get some food' -> general (exp: order, conf: 0.92, layer: llm)

5. 'Can I order a large pepperoni and how long will it take?' -> delivery (exp: order, conf: 0.66, layer: algorithmic)

6. 'I want to order but is delivery free?' -> order (exp: delivery, conf: 1.00, layer: algorithmic)

7. 'Can I order now or are you closed?' -> order (exp: hours_location, conf: 0.88, layer: algorithmic)

8. 'The delivery took forever' -> delivery (exp: complaint, conf: 0.68, layer: semantic)


Pipeline: Algorithmic -> Semantic -> LLM (Ollama)
Semantic Model: all-MiniLM-L6-v2
LLM Model: llama3.2:3b-instruct-q4_K_M
Mode: TEST MODE (intent recognition only)

Boost Engine: True
Edge Cases Included: False

Running tests on 213 queries...


OVERALL RESULTS
--------------------------------------------------------------------------------
Accuracy: 98.59%
Correct: 210 / 213
Avg Query Time: 23.0ms
Queries/s: 43.6

LAYER USAGE
--------------------------------------------------------------------------------
Algorithmic : 186 ( 87.3%)  Acc: 99.46%
Semantic    :  21 (  9.9%)  Acc: 90.48%
LLM         :   6 (  2.8%)  Acc: 100.00%

CONFIDENCE LEVELS
--------------------------------------------------------------------------------
High (â‰¥0.8)           : 151 ( 70.9%)
Medium (0.6-0.8)      :  52 ( 24.4%)
Low (<0.6)            :  10 (  4.7%)

INCORRECT PREDICTIONS
--------------------------------------------------------------------------------

1. 'I'll take a veggie deluxe no mushrooms' -> menu_inquiry (exp: order, conf: 0.59, layer: semantic)

2. 'The crust is hard as a rock' -> menu_inquiry (exp: complaint, conf: 0.60, layer: semantic)

3. 'Do you have late night hours' -> delivery (exp: hours_location, conf: 0.95, layer: algorithmic)

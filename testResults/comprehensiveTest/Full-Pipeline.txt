
================================================================================
COMPREHENSIVE TEST
================================================================================


Configuration:
  Algorithmic: True
  Semantic: True
  LLM: True
  Algorithmic Threshold: 0.65
  Semantic Threshold: 0.5
  Semantic Model: all-mpnet-base-v2
  LLM Backend: Ollama
  LLM Model: llama3.2:3b-instruct-q4_K_M
  Boost Engine: True
  Edge Cases: True

Test Dataset Size: 400 queries


OVERALL RESULTS
--------------------------------------------------------------------------------
Accuracy: 98.00%
Correct: 392 / 400
Avg Query Time: 24.6ms
Queries/s: 40.6

LAYER USAGE
--------------------------------------------------------------------------------
Algorithmic : 320 ( 80.0%)  Acc: 98.75%
Semantic    :  54 ( 13.5%)  Acc: 92.59%
LLM         :  26 (  6.5%)  Acc: 100.00%

LLM TOKEN USAGE
--------------------------------------------------------------------------------
Total Tokens: 6,407
Avg Tokens/Query: 16.0

CONFIDENCE LEVELS
--------------------------------------------------------------------------------
High (â‰¥0.8)           : 287 ( 71.8%)
Medium (0.6-0.8)      :  96 ( 24.0%)
Low (<0.6)            :  17 (  4.2%)

INCORRECT PREDICTIONS
--------------------------------------------------------------------------------

1. 'Driver still hasn't shown up' -> delivery (exp: complaint, conf: 0.62, layer: semantic)

2. 'What's your best seller?' -> hours_location (exp: menu_inquiry, conf: 0.75, layer: algorithmic)

3. 'How much would it cost to get my cold pizza replaced?' -> menu_inquiry (exp: complaint, conf: 0.65, layer: semantic)

4. 'Can I order a large pepperoni and how long will it take?' -> delivery (exp: order, conf: 0.66, layer: algorithmic)

5. 'I want to order but is delivery free?' -> order (exp: delivery, conf: 1.00, layer: algorithmic)

6. 'Can I order now or are you closed?' -> order (exp: hours_location, conf: 0.82, layer: algorithmic)

7. 'I don't like thick crust do you have thin' -> order (exp: menu_inquiry, conf: 0.64, layer: semantic)

8. 'The delivery took forever' -> delivery (exp: complaint, conf: 0.69, layer: semantic)

================================================================================
COMPREHENSIVE TEST
================================================================================


Pipeline: Algorithmic -> Semantic -> LLM (Ollama)
Semantic Model: all-mpnet-base-v2
LLM Model: llama3.2:3b-instruct-q4_K_M
Mode: TEST MODE (intent recognition only)

Boost Engine: False
Edge Cases Included: True

Test Dataset Size: 400 queries


OVERALL RESULTS
--------------------------------------------------------------------------------
Accuracy: 95.00%
Correct: 380 / 400
Avg Query Time: 32.7ms
Queries/s: 30.6

LAYER USAGE
--------------------------------------------------------------------------------
Algorithmic : 268 ( 67.0%)  Acc: 97.39%
Semantic    :  95 ( 23.8%)  Acc: 88.42%
LLM         :  37 (  9.2%)  Acc: 94.59%

LLM TOKEN USAGE
--------------------------------------------------------------------------------
Total Tokens: 596
Avg Tokens/Query: 1.5

CONFIDENCE LEVELS
--------------------------------------------------------------------------------
High (â‰¥0.8)           : 249 ( 62.3%)
Medium (0.6-0.8)      : 124 ( 31.0%)
Low (<0.6)            :  27 (  6.8%)

INCORRECT PREDICTIONS
--------------------------------------------------------------------------------

1. 'Order a large margherita' -> menu_inquiry (exp: order, conf: 0.54, layer: semantic)

2. 'Late delivery and cold food' -> delivery (exp: complaint, conf: 0.50, layer: semantic)

3. 'Driver still hasn't shown up' -> delivery (exp: complaint, conf: 0.62, layer: semantic)

4. 'What's your best seller?' -> hours_location (exp: menu_inquiry, conf: 0.75, layer: algorithmic)

5. 'How much is extra cheese' -> delivery (exp: menu_inquiry, conf: 0.67, layer: algorithmic)

6. 'still waiting on my pizza' -> order (exp: delivery, conf: 0.68, layer: semantic)

7. 'How much longer until my pizza gets here' -> order (exp: delivery, conf: 0.66, layer: semantic)

8. 'What are your recommended good options?' -> delivery (exp: menu_inquiry, conf: 0.84, layer: algorithmic)

9. 'How much would it cost to get my cold pizza replaced?' -> menu_inquiry (exp: complaint, conf: 0.65, layer: semantic)

10. 'I want to complain but also need to know your hours' -> hours_location (exp: complaint, conf: 0.73, layer: semantic)

11. 'I want to order but is delivery free?' -> order (exp: delivery, conf: 0.93, layer: algorithmic)

12. 'Can I order now or are you closed?' -> order (exp: hours_location, conf: 0.67, layer: algorithmic)

13. 'I don't like thick crust do you have thin' -> order (exp: menu_inquiry, conf: 0.64, layer: semantic)

14. 'Just what I needed, cold pizza again' -> order (exp: complaint, conf: 0.61, layer: semantic)

15. 'The delivery took forever' -> delivery (exp: complaint, conf: 0.69, layer: semantic)

16. 'Same order as before' -> complaint (exp: order, conf: 0.62, layer: semantic)

17. 'My oder is late' -> delivery (exp: complaint, conf: 0.92, layer: llm)

18. 'where u guys at' -> general (exp: hours_location, conf: 0.92, layer: llm)

19. 'I have a question about delivery' -> general (exp: delivery, conf: 0.84, layer: algorithmic)

20. 'Can I inquire about an order I placed for delivery?' -> order (exp: delivery, conf: 0.69, layer: algorithmic)


================================================================================
COMPARATIVE TEST
================================================================================


Testing multiple pipeline configurations for comparative results

Configuration:
  Algorithmic Threshold: 0.65
  Semantic Threshold: 0.5
  Semantic Model: all-mpnet-base-v2
  LLM Backend: Ollama
  LLM Model: llama3.2:3b-instruct-q4_K_M
  Boost Engine: True
  Edge Cases: False

Test Dataset Size: 295 queries


────────────────────────────────────────────────────────────────────────────────
Full Pipeline
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 99.32% (293/295 correct)
  Time: 4.99s | Avg: 16.9ms | 59.1 q/s
  Layers Used - Algo: 260, Semantic: 22, LLM: 13
  Tokens: 203 (0.7 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> Semantic
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 96.95% (286/295 correct)
  Time: 1.49s | Avg: 5.0ms | 198.6 q/s
  Layers Used - Algo: 260, Semantic: 30, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 98.64% (291/295 correct)
  Time: 9.63s | Avg: 32.6ms | 30.6 q/s
  Layers Used - Algo: 260, Semantic: 0, LLM: 35
  Tokens: 557 (1.9 avg/query)

────────────────────────────────────────────────────────────────────────────────
Semantic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 95.59% (282/295 correct)
  Time: 10.20s | Avg: 34.6ms | 28.9 q/s
  Layers Used - Algo: 0, Semantic: 273, LLM: 22
  Tokens: 347 (1.2 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 94.92% (280/295 correct)
  Time: 575.2ms | Avg: 1.9ms | 512.9 q/s
  Layers Used - Algo: 287, Semantic: 0, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Semantic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 92.88% (274/295 correct)
  Time: 3.18s | Avg: 10.8ms | 92.6 q/s
  Layers Used - Algo: 0, Semantic: 289, LLM: 0

────────────────────────────────────────────────────────────────────────────────
LLM Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 88.47% (261/295 correct)
  Time: 77.94s | Avg: 264.2ms | 3.8 q/s
  Layers Used - Algo: 0, Semantic: 0, LLM: 295
  Tokens: 4,698 (15.9 avg/query)

================================================================================
COMPARATIVE ANALYSIS
================================================================================


Pipeline Comparison
--------------------------------------------------------------------------------
Configuration             Accuracy   Total Time   Avg Time   Q/s
--------------------------------------------------------------------------------
Full Pipeline               99.32%       4.99s    16.9ms      59.1
Algorithmic -> Semantic     96.95%       1.49s     5.0ms     198.6
Algorithmic -> LLM          98.64%       9.63s    32.6ms      30.6
Semantic -> LLM             95.59%      10.20s    34.6ms      28.9
Algorithmic Only            94.92%     575.2ms     1.9ms     512.9
Semantic Only               92.88%       3.18s    10.8ms      92.6
LLM Only                    88.47%      77.94s   264.2ms       3.8

LAYER USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             Algo     Semantic   LLM      Unrecognized Intent
--------------------------------------------------------------------------------
Full Pipeline                260        22      13        0
Algorithmic -> Semantic      260        30       0        5
Algorithmic -> LLM           260         0      35        0
Semantic -> LLM                0       273      22        0
Algorithmic Only             287         0       0        8
Semantic Only                  0       289       0        6
LLM Only                       0         0     295        2

TOKEN USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             LLM Calls    Total Tokens    Avg/Query    vs Full Pipeline
--------------------------------------------------------------------------------
Full Pipeline                     13            203         0.7       baseline
Algorithmic -> LLM                35            557         1.9       + 174.4%
Semantic -> LLM                   22            347         1.2       +  70.9%
LLM Only                         295          4,698        15.9       +2214.3%

================================================================================
COMPARATIVE TEST
================================================================================


Testing multiple pipeline configurations for comparative results

Configuration:
  Algorithmic Threshold: 0.65
  Semantic Threshold: 0.5
  Semantic Model: all-mpnet-base-v2
  LLM Backend: Ollama
  LLM Model: llama3.2:3b-instruct-q4_K_M
  Boost Engine: True
  Edge Cases: True

Test Dataset Size: 400 queries


────────────────────────────────────────────────────────────────────────────────
Full Pipeline
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 98.00% (392/400 correct)
  Time: 9.96s | Avg: 24.9ms | 40.2 q/s
  Layers Used - Algo: 320, Semantic: 54, LLM: 26
  Tokens: 6,407 (16.0 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> Semantic
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 94.75% (379/400 correct)
  Time: 2.34s | Avg: 5.9ms | 170.6 q/s
  Layers Used - Algo: 320, Semantic: 72, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 96.50% (386/400 correct)
  Time: 22.17s | Avg: 55.4ms | 18.0 q/s
  Layers Used - Algo: 320, Semantic: 0, LLM: 80
  Tokens: 19,894 (49.7 avg/query)

────────────────────────────────────────────────────────────────────────────────
Semantic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 93.50% (374/400 correct)
  Time: 17.77s | Avg: 44.4ms | 22.5 q/s
  Layers Used - Algo: 0, Semantic: 354, LLM: 46
  Tokens: 11,346 (28.4 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 90.25% (361/400 correct)
  Time: 1.37s | Avg: 3.4ms | 292.6 q/s
  Layers Used - Algo: 381, Semantic: 0, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Semantic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 89.25% (357/400 correct)
  Time: 7.30s | Avg: 18.3ms | 54.8 q/s
  Layers Used - Algo: 0, Semantic: 386, LLM: 0

────────────────────────────────────────────────────────────────────────────────
LLM Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 86.00% (344/400 correct)
  Time: 104.89s | Avg: 262.2ms | 3.8 q/s
  Layers Used - Algo: 0, Semantic: 0, LLM: 400
  Tokens: 99,301 (248.3 avg/query)

================================================================================
COMPARATIVE ANALYSIS
================================================================================


Pipeline Comparison
--------------------------------------------------------------------------------
Configuration             Accuracy   Total Time   Avg Time   Q/s
--------------------------------------------------------------------------------
Full Pipeline               98.00%       9.96s    24.9ms      40.2
Algorithmic -> Semantic     94.75%       2.34s     5.9ms     170.6
Algorithmic -> LLM          96.50%      22.17s    55.4ms      18.0
Semantic -> LLM             93.50%      17.77s    44.4ms      22.5
Algorithmic Only            90.25%       1.37s     3.4ms     292.6
Semantic Only               89.25%       7.30s    18.3ms      54.8
LLM Only                    86.00%     104.89s   262.2ms       3.8

LAYER USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             Algo     Semantic   LLM      Unrecognized Intent
--------------------------------------------------------------------------------
Full Pipeline                320        54      26        0
Algorithmic -> Semantic      320        72       0        8
Algorithmic -> LLM           320         0      80        0
Semantic -> LLM                0       354      46        0
Algorithmic Only             381         0       0       19
Semantic Only                  0       386       0       14
LLM Only                       0         0     400        0

TOKEN USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             LLM Calls    Total Tokens    Avg/Query    vs Full Pipeline
--------------------------------------------------------------------------------
Full Pipeline                     26          6,407        16.0       baseline
Algorithmic -> LLM                80         19,894        49.7       + 210.5%
Semantic -> LLM                   46         11,346        28.4       +  77.1%
LLM Only                         400         99,301       248.3       +1449.9%

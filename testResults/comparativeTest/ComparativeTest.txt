
================================================================================
COMPARATIVE TEST
================================================================================


Testing multiple pipeline configurations for comparative results

Configuration:
  Algorithmic Threshold: 0.65
  Semantic Threshold: 0.5
  Semantic Model: all-mpnet-base-v2
  LLM Backend: Ollama
  LLM Model: llama3.2:3b-instruct-q4_K_M
  Boost Engine: True
  Edge Cases: True

Test Dataset Size: 600 queries


────────────────────────────────────────────────────────────────────────────────
Full Pipeline
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 97.33% (584/600 correct)
  Time: 18.86s | Avg: 31.4ms | 31.8 q/s
  Layers Used - Algo: 436, Semantic: 108, LLM: 56
  Tokens: 13,339 (22.2 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> Semantic
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 91.67% (550/600 correct)
  Time: 2.45s | Avg: 4.1ms | 244.8 q/s
  Layers Used - Algo: 436, Semantic: 135, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 96.17% (577/600 correct)
  Time: 45.16s | Avg: 75.3ms | 13.3 q/s
  Layers Used - Algo: 436, Semantic: 0, LLM: 164
  Tokens: 39,376 (65.6 avg/query)

────────────────────────────────────────────────────────────────────────────────
Semantic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 93.00% (558/600 correct)
  Time: 33.66s | Avg: 56.1ms | 17.8 q/s
  Layers Used - Algo: 0, Semantic: 516, LLM: 84
  Tokens: 20,043 (33.4 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 85.00% (510/600 correct)
  Time: 328.9ms | Avg: 0.5ms | 1824.2 q/s
  Layers Used - Algo: 551, Semantic: 0, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Semantic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 86.17% (517/600 correct)
  Time: 8.24s | Avg: 13.7ms | 72.8 q/s
  Layers Used - Algo: 0, Semantic: 561, LLM: 0

────────────────────────────────────────────────────────────────────────────────
LLM Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 87.17% (523/600 correct)
  Time: 167.34s | Avg: 278.9ms | 3.6 q/s
  Layers Used - Algo: 0, Semantic: 0, LLM: 600
  Tokens: 144,129 (240.2 avg/query)

================================================================================
COMPARATIVE ANALYSIS
================================================================================


Pipeline Comparison
--------------------------------------------------------------------------------
Configuration             Accuracy   Total Time   Avg Time   Q/s
--------------------------------------------------------------------------------
Full Pipeline               97.33%      18.86s    31.4ms      31.8
Algorithmic -> Semantic     91.67%       2.45s     4.1ms     244.8
Algorithmic -> LLM          96.17%      45.16s    75.3ms      13.3
Semantic -> LLM             93.00%      33.66s    56.1ms      17.8
Algorithmic Only            85.00%     328.9ms     0.5ms    1824.2
Semantic Only               86.17%       8.24s    13.7ms      72.8
LLM Only                    87.17%     167.34s   278.9ms       3.6

LAYER USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             Algo     Semantic   LLM      Unrecognized Intent
--------------------------------------------------------------------------------
Full Pipeline                436       108      56        0
Algorithmic -> Semantic      436       135       0       29
Algorithmic -> LLM           436         0     164        0
Semantic -> LLM                0       516      84        0
Algorithmic Only             551         0       0       49
Semantic Only                  0       561       0       39
LLM Only                       0         0     600        0

TOKEN USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             LLM Calls    Total Tokens    Avg/Query    vs Full Pipeline
--------------------------------------------------------------------------------
Full Pipeline                     56         13,339        22.2       baseline
Algorithmic -> LLM               164         39,376        65.6       + 195.2%
Semantic -> LLM                   84         20,043        33.4       +  50.3%
LLM Only                         600        144,129       240.2       + 980.5%

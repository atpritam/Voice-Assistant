
================================================================================
COMPARATIVE TEST
================================================================================


Testing multiple pipeline configurations for comparative results

Configuration:
  Algorithmic Threshold: 0.65
  Semantic Threshold: 0.5
  Semantic Model: all-mpnet-base-v2
  LLM Backend: Ollama
  LLM Model: gpt-oss:120b-cloud
  Boost Engine: True
  Edge Cases: True

Test Dataset Size: 600 queries


────────────────────────────────────────────────────────────────────────────────
Full Pipeline
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 97.50% (585/600 correct)
  Time: 64.06s | Avg: 106.8ms | 9.4 q/s
  Layers Used - Algo: 436, Semantic: 108, LLM: 56
  Tokens: 20,433 (34.1 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> Semantic
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 91.67% (550/600 correct)
  Time: 2.23s | Avg: 3.7ms | 269.5 q/s
  Layers Used - Algo: 436, Semantic: 135, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Algorithmic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 97.00% (582/600 correct)
  Time: 178.68s | Avg: 297.8ms | 3.4 q/s
  Layers Used - Algo: 436, Semantic: 0, LLM: 164
  Tokens: 59,354 (98.9 avg/query)

────────────────────────────────────────────────────────────────────────────────
Semantic -> LLM
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 93.67% (562/600 correct)
  Time: 104.49s | Avg: 174.2ms | 5.7 q/s
  Layers Used - Algo: 0, Semantic: 516, LLM: 84
  Tokens: 31,312 (52.2 avg/query)

────────────────────────────────────────────────────────────────────────────────
Algorithmic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 85.00% (510/600 correct)
  Time: 313.8ms | Avg: 0.5ms | 1912.1 q/s
  Layers Used - Algo: 551, Semantic: 0, LLM: 0

────────────────────────────────────────────────────────────────────────────────
Semantic Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 86.17% (517/600 correct)
  Time: 7.02s | Avg: 11.7ms | 85.4 q/s
  Layers Used - Algo: 0, Semantic: 561, LLM: 0

────────────────────────────────────────────────────────────────────────────────
LLM Only
────────────────────────────────────────────────────────────────────────────────
✓ Accuracy: 94.83% (569/600 correct)
  Time: 617.01s | Avg: 1.03s | 1.0 q/s
  Layers Used - Algo: 0, Semantic: 0, LLM: 600
  Tokens: 216,592 (361.0 avg/query)

================================================================================
COMPARATIVE ANALYSIS
================================================================================


Pipeline Comparison
--------------------------------------------------------------------------------
Configuration             Accuracy   Total Time   Avg Time   Q/s
--------------------------------------------------------------------------------
Full Pipeline               97.50%      64.06s   106.8ms       9.4
Algorithmic -> Semantic     91.67%       2.23s     3.7ms     269.5
Algorithmic -> LLM          97.00%     178.68s   297.8ms       3.4
Semantic -> LLM             93.67%     104.49s   174.2ms       5.7
Algorithmic Only            85.00%     313.8ms     0.5ms    1912.1
Semantic Only               86.17%       7.02s    11.7ms      85.4
LLM Only                    94.83%     617.01s     1.03s       1.0

LAYER USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             Algo     Semantic   LLM      Unrecognized Intent
--------------------------------------------------------------------------------
Full Pipeline                436       108      56        0
Algorithmic -> Semantic      436       135       0       29
Algorithmic -> LLM           436         0     164        0
Semantic -> LLM                0       516      84        0
Algorithmic Only             551         0       0       49
Semantic Only                  0       561       0       39
LLM Only                       0         0     600        0

TOKEN USAGE COMPARISON
--------------------------------------------------------------------------------
Configuration             LLM Calls    Total Tokens    Avg/Query    vs Full Pipeline
--------------------------------------------------------------------------------
Full Pipeline                     56         20,433        34.1       baseline
Algorithmic -> LLM               164         59,354        98.9       + 190.5%
Semantic -> LLM                   84         31,312        52.2       +  53.2%
LLM Only                         600        216,592       361.0       + 960.0%